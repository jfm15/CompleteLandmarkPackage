-----------Arguments-----------
{'cfg': 'experiments/ultra_hip/dhd.yaml', 'images': '/experiments/datasets-in-use/ultrasound-hip-baby-land-seg/images/img', 'annotations': '/experiments/datasets-in-use/ultrasound-hip-baby-land-seg/annotations', 'partition': '/experiments/datasets-in-use/ultrasound-hip-baby-land-seg/partitions/partition_alpha_angle_0.7_0.15_0.15_0.06552.json', 'pretrained_model': '/experiments/medimaging/experimentsallisonclement/CompleteLandmarkPackage/output/dhd/run:2_models/dhd_model_run:2_idx:0.pth'}

-----------Configuration-----------
DATASET:
  AUGMENTATION:
    ELASTIC_SMOOTHNESS: 0
    ELASTIC_STRENGTH: 0
    FLIP: False
    FLIP_PAIRS: []
    INTENSITY_FACTOR: 0.5
    REVERSE_AXIS: False
    ROTATION_FACTOR: 5
    SF: 0.2
    TRANSLATION_X: 0.05
    TRANSLATION_Y: 0.1
  CACHED_IMAGE_SIZE: [640, 480]
  CACHE_DIR: cache/ultra_hip/
  DELIMITER: ,
  DIR: 
  FLIP_AXIS: True
  GROUND_TRUTH_MULTIPLIER: 1.0
  IMAGE_EXT: .jpg
  KEY_POINTS: 5
  NO_OF_ANNOTATORS: 1
  PIXEL_SIZE: [1.0, 1.0]
  SIGMA: 5
  STATIONARY_POINTS: []
  STATIONARY_POINT_DISTANCE: 0
  USE_COLS: (0, 1)
MODEL:
  DECODER_CHANNELS: [256, 256, 256, 128, 64]
  ENCODER_NAME: resnet34
  ENCODER_WEIGHTS: imagenet
  IN_CHANNELS: 1
  NAME: UnetPlusPlus
TRAIN:
  BATCH_SIZE: 3
  EARLY_STOPPING: 5
  ENSEMBLE_MODELS: 1
  EPOCHS: 30
  FINAL_LAYER: two_d_softmax
  FINE_TUNE_EPOCHS: 0
  FRACTIONALISE_IMAGES: False
  LABELED_SUBSET: 150
  LOSS_FUNCTION: nll_across_batch
  LR: 0.001
  REPEATS: 3
  USE_UNLABELED: False
VALIDATION:
  AGGREGATION_METHODS: ['mean average', 'confidence weighted']
  DIAGNOSES: ['ddh']
  MEASUREMENTS: ['alpha_angle', 'beta_angle']
  MEASUREMENTS_SUFFIX: ultra
  SAVE_IMAGE_PATH: images/ultra_hip/
  SDR_AGGREGATION_METHOD: confidence weighted
  SDR_THRESHOLDS: [2.0, 2.5, 3.0, 4.0]

-----------Model Summary-----------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 320, 240]           3,136
       BatchNorm2d-2         [-1, 64, 320, 240]             128
              ReLU-3         [-1, 64, 320, 240]               0
         MaxPool2d-4         [-1, 64, 160, 120]               0
            Conv2d-5         [-1, 64, 160, 120]          36,864
       BatchNorm2d-6         [-1, 64, 160, 120]             128
              ReLU-7         [-1, 64, 160, 120]               0
            Conv2d-8         [-1, 64, 160, 120]          36,864
       BatchNorm2d-9         [-1, 64, 160, 120]             128
             ReLU-10         [-1, 64, 160, 120]               0
       BasicBlock-11         [-1, 64, 160, 120]               0
           Conv2d-12         [-1, 64, 160, 120]          36,864
      BatchNorm2d-13         [-1, 64, 160, 120]             128
             ReLU-14         [-1, 64, 160, 120]               0
           Conv2d-15         [-1, 64, 160, 120]          36,864
      BatchNorm2d-16         [-1, 64, 160, 120]             128
             ReLU-17         [-1, 64, 160, 120]               0
       BasicBlock-18         [-1, 64, 160, 120]               0
           Conv2d-19         [-1, 64, 160, 120]          36,864
      BatchNorm2d-20         [-1, 64, 160, 120]             128
             ReLU-21         [-1, 64, 160, 120]               0
           Conv2d-22         [-1, 64, 160, 120]          36,864
      BatchNorm2d-23         [-1, 64, 160, 120]             128
             ReLU-24         [-1, 64, 160, 120]               0
       BasicBlock-25         [-1, 64, 160, 120]               0
           Conv2d-26          [-1, 128, 80, 60]          73,728
      BatchNorm2d-27          [-1, 128, 80, 60]             256
             ReLU-28          [-1, 128, 80, 60]               0
           Conv2d-29          [-1, 128, 80, 60]         147,456
      BatchNorm2d-30          [-1, 128, 80, 60]             256
           Conv2d-31          [-1, 128, 80, 60]           8,192
      BatchNorm2d-32          [-1, 128, 80, 60]             256
             ReLU-33          [-1, 128, 80, 60]               0
       BasicBlock-34          [-1, 128, 80, 60]               0
           Conv2d-35          [-1, 128, 80, 60]         147,456
      BatchNorm2d-36          [-1, 128, 80, 60]             256
             ReLU-37          [-1, 128, 80, 60]               0
           Conv2d-38          [-1, 128, 80, 60]         147,456
      BatchNorm2d-39          [-1, 128, 80, 60]             256
             ReLU-40          [-1, 128, 80, 60]               0
       BasicBlock-41          [-1, 128, 80, 60]               0
           Conv2d-42          [-1, 128, 80, 60]         147,456
      BatchNorm2d-43          [-1, 128, 80, 60]             256
             ReLU-44          [-1, 128, 80, 60]               0
           Conv2d-45          [-1, 128, 80, 60]         147,456
      BatchNorm2d-46          [-1, 128, 80, 60]             256
             ReLU-47          [-1, 128, 80, 60]               0
       BasicBlock-48          [-1, 128, 80, 60]               0
           Conv2d-49          [-1, 128, 80, 60]         147,456
      BatchNorm2d-50          [-1, 128, 80, 60]             256
             ReLU-51          [-1, 128, 80, 60]               0
           Conv2d-52          [-1, 128, 80, 60]         147,456
      BatchNorm2d-53          [-1, 128, 80, 60]             256
             ReLU-54          [-1, 128, 80, 60]               0
       BasicBlock-55          [-1, 128, 80, 60]               0
           Conv2d-56          [-1, 256, 40, 30]         294,912
      BatchNorm2d-57          [-1, 256, 40, 30]             512
             ReLU-58          [-1, 256, 40, 30]               0
           Conv2d-59          [-1, 256, 40, 30]         589,824
      BatchNorm2d-60          [-1, 256, 40, 30]             512
           Conv2d-61          [-1, 256, 40, 30]          32,768
      BatchNorm2d-62          [-1, 256, 40, 30]             512
             ReLU-63          [-1, 256, 40, 30]               0
       BasicBlock-64          [-1, 256, 40, 30]               0
           Conv2d-65          [-1, 256, 40, 30]         589,824
      BatchNorm2d-66          [-1, 256, 40, 30]             512
             ReLU-67          [-1, 256, 40, 30]               0
           Conv2d-68          [-1, 256, 40, 30]         589,824
      BatchNorm2d-69          [-1, 256, 40, 30]             512
             ReLU-70          [-1, 256, 40, 30]               0
       BasicBlock-71          [-1, 256, 40, 30]               0
           Conv2d-72          [-1, 256, 40, 30]         589,824
      BatchNorm2d-73          [-1, 256, 40, 30]             512
             ReLU-74          [-1, 256, 40, 30]               0
           Conv2d-75          [-1, 256, 40, 30]         589,824
      BatchNorm2d-76          [-1, 256, 40, 30]             512
             ReLU-77          [-1, 256, 40, 30]               0
       BasicBlock-78          [-1, 256, 40, 30]               0
           Conv2d-79          [-1, 256, 40, 30]         589,824
      BatchNorm2d-80          [-1, 256, 40, 30]             512
             ReLU-81          [-1, 256, 40, 30]               0
           Conv2d-82          [-1, 256, 40, 30]         589,824
      BatchNorm2d-83          [-1, 256, 40, 30]             512
             ReLU-84          [-1, 256, 40, 30]               0
       BasicBlock-85          [-1, 256, 40, 30]               0
           Conv2d-86          [-1, 256, 40, 30]         589,824
      BatchNorm2d-87          [-1, 256, 40, 30]             512
             ReLU-88          [-1, 256, 40, 30]               0
           Conv2d-89          [-1, 256, 40, 30]         589,824
      BatchNorm2d-90          [-1, 256, 40, 30]             512
             ReLU-91          [-1, 256, 40, 30]               0
       BasicBlock-92          [-1, 256, 40, 30]               0
           Conv2d-93          [-1, 256, 40, 30]         589,824
      BatchNorm2d-94          [-1, 256, 40, 30]             512
             ReLU-95          [-1, 256, 40, 30]               0
           Conv2d-96          [-1, 256, 40, 30]         589,824
      BatchNorm2d-97          [-1, 256, 40, 30]             512
             ReLU-98          [-1, 256, 40, 30]               0
       BasicBlock-99          [-1, 256, 40, 30]               0
          Conv2d-100          [-1, 512, 20, 15]       1,179,648
     BatchNorm2d-101          [-1, 512, 20, 15]           1,024
            ReLU-102          [-1, 512, 20, 15]               0
          Conv2d-103          [-1, 512, 20, 15]       2,359,296
     BatchNorm2d-104          [-1, 512, 20, 15]           1,024
          Conv2d-105          [-1, 512, 20, 15]         131,072
     BatchNorm2d-106          [-1, 512, 20, 15]           1,024
            ReLU-107          [-1, 512, 20, 15]               0
      BasicBlock-108          [-1, 512, 20, 15]               0
          Conv2d-109          [-1, 512, 20, 15]       2,359,296
     BatchNorm2d-110          [-1, 512, 20, 15]           1,024
            ReLU-111          [-1, 512, 20, 15]               0
          Conv2d-112          [-1, 512, 20, 15]       2,359,296
     BatchNorm2d-113          [-1, 512, 20, 15]           1,024
            ReLU-114          [-1, 512, 20, 15]               0
      BasicBlock-115          [-1, 512, 20, 15]               0
          Conv2d-116          [-1, 512, 20, 15]       2,359,296
     BatchNorm2d-117          [-1, 512, 20, 15]           1,024
            ReLU-118          [-1, 512, 20, 15]               0
          Conv2d-119          [-1, 512, 20, 15]       2,359,296
     BatchNorm2d-120          [-1, 512, 20, 15]           1,024
            ReLU-121          [-1, 512, 20, 15]               0
      BasicBlock-122          [-1, 512, 20, 15]               0
   ResNetEncoder-123  [[-1, 1, 640, 480], [-1, 64, 320, 240], [-1, 64, 160, 120], [-1, 128, 80, 60], [-1, 256, 40, 30], [-1, 512, 20, 15]]               0
        Identity-124          [-1, 768, 40, 30]               0
       Attention-125          [-1, 768, 40, 30]               0
          Conv2d-126          [-1, 256, 40, 30]       1,769,472
     BatchNorm2d-127          [-1, 256, 40, 30]             512
            ReLU-128          [-1, 256, 40, 30]               0
          Conv2d-129          [-1, 256, 40, 30]         589,824
     BatchNorm2d-130          [-1, 256, 40, 30]             512
            ReLU-131          [-1, 256, 40, 30]               0
        Identity-132          [-1, 256, 40, 30]               0
       Attention-133          [-1, 256, 40, 30]               0
    DecoderBlock-134          [-1, 256, 40, 30]               0
        Identity-135          [-1, 384, 80, 60]               0
       Attention-136          [-1, 384, 80, 60]               0
          Conv2d-137          [-1, 128, 80, 60]         442,368
     BatchNorm2d-138          [-1, 128, 80, 60]             256
            ReLU-139          [-1, 128, 80, 60]               0
          Conv2d-140          [-1, 128, 80, 60]         147,456
     BatchNorm2d-141          [-1, 128, 80, 60]             256
            ReLU-142          [-1, 128, 80, 60]               0
        Identity-143          [-1, 128, 80, 60]               0
       Attention-144          [-1, 128, 80, 60]               0
    DecoderBlock-145          [-1, 128, 80, 60]               0
        Identity-146        [-1, 192, 160, 120]               0
       Attention-147        [-1, 192, 160, 120]               0
          Conv2d-148         [-1, 64, 160, 120]         110,592
     BatchNorm2d-149         [-1, 64, 160, 120]             128
            ReLU-150         [-1, 64, 160, 120]               0
          Conv2d-151         [-1, 64, 160, 120]          36,864
     BatchNorm2d-152         [-1, 64, 160, 120]             128
            ReLU-153         [-1, 64, 160, 120]               0
        Identity-154         [-1, 64, 160, 120]               0
       Attention-155         [-1, 64, 160, 120]               0
    DecoderBlock-156         [-1, 64, 160, 120]               0
        Identity-157        [-1, 128, 320, 240]               0
       Attention-158        [-1, 128, 320, 240]               0
          Conv2d-159         [-1, 64, 320, 240]          73,728
     BatchNorm2d-160         [-1, 64, 320, 240]             128
            ReLU-161         [-1, 64, 320, 240]               0
          Conv2d-162         [-1, 64, 320, 240]          36,864
     BatchNorm2d-163         [-1, 64, 320, 240]             128
            ReLU-164         [-1, 64, 320, 240]               0
        Identity-165         [-1, 64, 320, 240]               0
       Attention-166         [-1, 64, 320, 240]               0
    DecoderBlock-167         [-1, 64, 320, 240]               0
        Identity-168          [-1, 512, 80, 60]               0
       Attention-169          [-1, 512, 80, 60]               0
          Conv2d-170          [-1, 256, 80, 60]       1,179,648
     BatchNorm2d-171          [-1, 256, 80, 60]             512
            ReLU-172          [-1, 256, 80, 60]               0
          Conv2d-173          [-1, 256, 80, 60]         589,824
     BatchNorm2d-174          [-1, 256, 80, 60]             512
            ReLU-175          [-1, 256, 80, 60]               0
        Identity-176          [-1, 256, 80, 60]               0
       Attention-177          [-1, 256, 80, 60]               0
    DecoderBlock-178          [-1, 256, 80, 60]               0
        Identity-179        [-1, 256, 160, 120]               0
       Attention-180        [-1, 256, 160, 120]               0
          Conv2d-181         [-1, 64, 160, 120]         147,456
     BatchNorm2d-182         [-1, 64, 160, 120]             128
            ReLU-183         [-1, 64, 160, 120]               0
          Conv2d-184         [-1, 64, 160, 120]          36,864
     BatchNorm2d-185         [-1, 64, 160, 120]             128
            ReLU-186         [-1, 64, 160, 120]               0
        Identity-187         [-1, 64, 160, 120]               0
       Attention-188         [-1, 64, 160, 120]               0
    DecoderBlock-189         [-1, 64, 160, 120]               0
        Identity-190        [-1, 192, 320, 240]               0
       Attention-191        [-1, 192, 320, 240]               0
          Conv2d-192         [-1, 64, 320, 240]         110,592
     BatchNorm2d-193         [-1, 64, 320, 240]             128
            ReLU-194         [-1, 64, 320, 240]               0
          Conv2d-195         [-1, 64, 320, 240]          36,864
     BatchNorm2d-196         [-1, 64, 320, 240]             128
            ReLU-197         [-1, 64, 320, 240]               0
        Identity-198         [-1, 64, 320, 240]               0
       Attention-199         [-1, 64, 320, 240]               0
    DecoderBlock-200         [-1, 64, 320, 240]               0
        Identity-201        [-1, 448, 160, 120]               0
       Attention-202        [-1, 448, 160, 120]               0
          Conv2d-203        [-1, 256, 160, 120]       1,032,192
     BatchNorm2d-204        [-1, 256, 160, 120]             512
            ReLU-205        [-1, 256, 160, 120]               0
          Conv2d-206        [-1, 256, 160, 120]         589,824
     BatchNorm2d-207        [-1, 256, 160, 120]             512
            ReLU-208        [-1, 256, 160, 120]               0
        Identity-209        [-1, 256, 160, 120]               0
       Attention-210        [-1, 256, 160, 120]               0
    DecoderBlock-211        [-1, 256, 160, 120]               0
        Identity-212        [-1, 256, 320, 240]               0
       Attention-213        [-1, 256, 320, 240]               0
          Conv2d-214         [-1, 64, 320, 240]         147,456
     BatchNorm2d-215         [-1, 64, 320, 240]             128
            ReLU-216         [-1, 64, 320, 240]               0
          Conv2d-217         [-1, 64, 320, 240]          36,864
     BatchNorm2d-218         [-1, 64, 320, 240]             128
            ReLU-219         [-1, 64, 320, 240]               0
        Identity-220         [-1, 64, 320, 240]               0
       Attention-221         [-1, 64, 320, 240]               0
    DecoderBlock-222         [-1, 64, 320, 240]               0
        Identity-223        [-1, 512, 320, 240]               0
       Attention-224        [-1, 512, 320, 240]               0
          Conv2d-225        [-1, 128, 320, 240]         589,824
     BatchNorm2d-226        [-1, 128, 320, 240]             256
            ReLU-227        [-1, 128, 320, 240]               0
          Conv2d-228        [-1, 128, 320, 240]         147,456
     BatchNorm2d-229        [-1, 128, 320, 240]             256
            ReLU-230        [-1, 128, 320, 240]               0
        Identity-231        [-1, 128, 320, 240]               0
       Attention-232        [-1, 128, 320, 240]               0
    DecoderBlock-233        [-1, 128, 320, 240]               0
          Conv2d-234         [-1, 64, 640, 480]          73,728
     BatchNorm2d-235         [-1, 64, 640, 480]             128
            ReLU-236         [-1, 64, 640, 480]               0
          Conv2d-237         [-1, 64, 640, 480]          36,864
     BatchNorm2d-238         [-1, 64, 640, 480]             128
            ReLU-239         [-1, 64, 640, 480]               0
        Identity-240         [-1, 64, 640, 480]               0
       Attention-241         [-1, 64, 640, 480]               0
    DecoderBlock-242         [-1, 64, 640, 480]               0
UnetPlusPlusDecoder-243         [-1, 64, 640, 480]               0
          Conv2d-244          [-1, 5, 640, 480]           2,885
        Identity-245          [-1, 5, 640, 480]               0
        Identity-246          [-1, 5, 640, 480]               0
      Activation-247          [-1, 5, 640, 480]               0
    UnetPlusPlus-248          [-1, 5, 640, 480]               0
    UnetPlusPlus-249          [-1, 5, 640, 480]               0
================================================================
Total params: 29,249,541
Trainable params: 29,249,541
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 1.17
Forward/backward pass size (MB): 6118.36
Params size (MB): 111.58
Estimated Total Size (MB): 6231.11
----------------------------------------------------------------

-----------Validation Set-----------

-----------Final Statistics-----------
Average loss: 5.896
